# Scheduled Agents

Scheduled agents run outside of interactive sessions on a recurring schedule. They perform maintenance, audits, and health checks automatically — catching issues before humans or interactive agents encounter them.

## Architecture

```
┌─────────────────────┐
│  OS Scheduler        │  cron (Linux) / launchd (macOS)
│  (fires on schedule) │  Catches up after sleep/shutdown
└────────┬────────────┘
         │ spawns
         ▼
┌─────────────────────┐     ┌──────────────────────┐
│  Agent Shell Script  │────▶│  Copilot CLI (headless) │
│  (bash)              │     │  copilot -p "prompt"    │
└────────┬────────────┘     └──────────┬─────────────┘
         │                             │ writes
         ▼                             ▼
┌─────────────────────┐     ┌──────────────────────┐
│  docs/agents/        │     │  docs/agents/          │
│  agent-report.md     │     │  shared-context.md     │
│  (individual report) │     │  (cross-agent intel)   │
└─────────────────────┘     └──────────────────────┘
```

**Key idea:** Each agent is a standalone bash script that invokes the Copilot CLI in headless mode (`copilot -p "prompt"`). Agents write markdown reports to disk. An optional admin panel reads those reports and displays health status.

## Agent Shell Script Template

```bash
#!/bin/bash
# scripts/agents/my-agent.sh

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/../.." && pwd)"

AGENT_NAME="my-agent"
REPORT_FILE="docs/agents/${AGENT_NAME}-report.md"

# ── 1. Read shared context from other agents ──
SHARED_CONTEXT=""
if [ -f "$PROJECT_ROOT/docs/agents/shared-context.md" ]; then
  SHARED_CONTEXT=$(cat "$PROJECT_ROOT/docs/agents/shared-context.md")
fi

# ── 2. Build the prompt ──
PROMPT="You are the $AGENT_NAME scheduled agent for this project.

Your responsibilities:
[Define agent-specific responsibilities here]

## Context from Other Agents
$SHARED_CONTEXT

After completing your analysis, append a SHARED_CONTEXT block to docs/agents/shared-context.md with your key findings and any cross-agent recommendations."

# ── 3. Run Copilot CLI in headless mode ──
cd "$PROJECT_ROOT"
echo "[$(date)] Starting $AGENT_NAME agent..."

copilot -p "$PROMPT" \
  > "$REPORT_FILE" 2>&1

echo "[$(date)] $AGENT_NAME complete. Report: $REPORT_FILE"
```

### Key Design Choices

- **`set -euo pipefail`** — Fail fast on errors. Don't silently continue if the CLI crashes.
- **Shared context** — Agents read other agents' findings before starting, building on each other's intelligence.
- **`copilot -p`** — The Copilot CLI's headless mode. Unlike the interactive VS Code chat, this runs in a terminal with full tool access.

## Scheduling

### macOS (launchd)

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
  <key>Label</key>
  <string>com.project.agent.my-agent</string>
  <key>ProgramArguments</key>
  <array>
    <string>/absolute/path/to/project/scripts/agents/my-agent.sh</string>
  </array>
  <key>StartCalendarInterval</key>
  <dict>
    <key>Hour</key>
    <integer>6</integer>
    <key>Minute</key>
    <integer>0</integer>
  </dict>
  <key>StandardOutPath</key>
  <string>/absolute/path/to/project/logs/my-agent.log</string>
  <key>StandardErrorPath</key>
  <string>/absolute/path/to/project/logs/my-agent.error.log</string>
</dict>
</plist>
```

```bash
# Install:
cp com.project.agent.my-agent.plist ~/Library/LaunchAgents/
launchctl load ~/Library/LaunchAgents/com.project.agent.my-agent.plist

# Uninstall:
launchctl unload ~/Library/LaunchAgents/com.project.agent.my-agent.plist
```

### Linux (cron)

```bash
# Run daily at 6:00 AM:
0 6 * * * /absolute/path/to/project/scripts/agents/my-agent.sh >> /absolute/path/to/project/logs/my-agent.log 2>&1
```

## Common Agent Types

| Agent | Schedule | Focus |
|-------|----------|-------|
| **Test health** | Daily | Run full test suite, check for flaky tests (run 3x), report coverage |
| **Security audit** | Weekly | Dependency vulnerabilities, secret scanning, license compliance |
| **Code quality** | Daily | Lint, dead code, TODO/FIXME count, TypeScript strict violations |
| **Dependency health** | Weekly | Outdated packages, version conflicts, lockfile integrity |
| **Performance check** | Weekly | Bundle sizes, build times, regression detection |
| **Documentation sync** | Weekly | Stale docs, undocumented public APIs, broken links |

## Concrete Agent Prompts

### Test Health Agent

```bash
PROMPT="You are the test-health scheduled agent.

Run the full test suite 3 times to detect flaky tests:
1. Run: pnpm run test --reporter json 2>&1
2. Record which tests pass/fail on each run
3. Flag any test that fails on at least 1 of 3 runs as FLAKY
4. Report: total tests, pass rate, flaky tests (with file:line), coverage if available

Write your report to docs/agents/test-health-report.md with sections:
- Summary (1 line: GREEN/YELLOW/RED + pass rate)
- Flaky Tests (file:line + failure message for each)
- Failed Tests (consistently failing)
- Coverage Changes (if measurable)

Append to shared-context.md:
- Overall status
- Any flaky tests that other agents should know about"
```

### Security Audit Agent

```bash
PROMPT="You are the security-audit scheduled agent.

Perform these checks:
1. Run: pnpm audit --json 2>&1 (or npm audit / pip audit)
2. Search for hardcoded secrets: grep for API keys, tokens, passwords in source files
3. Check .env.example against actual env var usage — flag undocumented vars
4. Check for injection vectors: unsanitized user input in SQL, shell commands, HTML
5. Verify CORS configuration if applicable

Write your report to docs/agents/security-audit-report.md with sections:
- Summary (1 line: GREEN/YELLOW/RED + critical count)
- Dependency Vulnerabilities (severity, package, recommendation)
- Hardcoded Secrets (file:line — DO NOT include the actual secret)
- Injection Risks (file:line + type)
- Configuration Issues

Append to shared-context.md:
- Critical vulnerabilities count
- Any findings that affect other agents' domains"
```

### Code Quality Agent

```bash
PROMPT="You are the code-quality scheduled agent.

Perform these checks:
1. Run: pnpm run lint --format json 2>&1
2. Run: pnpm run typecheck 2>&1
3. Search for TODO/FIXME/HACK comments and count by category
4. Identify dead code: exported functions with zero import references
5. Check for files over 500 lines (complexity indicator)

Write your report to docs/agents/code-quality-report.md with sections:
- Summary (1 line: GREEN/YELLOW/RED + issue count)
- Lint Issues (count by rule, top 5 most frequent)
- Type Errors (count + file:line for each)
- Technical Debt (TODO/FIXME/HACK counts + examples)
- Large Files (path + line count)
- Dead Code Candidates (exported but never imported)

Append to shared-context.md:
- Issue counts by category
- New issues since last run (if previous report exists)"
```

### Dependency Health Agent

```bash
PROMPT="You are the dependency-health scheduled agent.

Perform these checks:
1. Check for outdated packages: pnpm outdated --format json 2>&1
2. Identify major version bumps available (breaking changes)
3. Verify lockfile integrity: pnpm install --frozen-lockfile 2>&1
4. Check for duplicate packages in the dependency tree
5. Flag packages with no recent updates (>2 years, possible abandonment)

Write your report to docs/agents/dependency-health-report.md with sections:
- Summary (1 line: GREEN/YELLOW/RED + outdated count)
- Critical Updates (security patches, major versions behind)
- Outdated Packages (name, current, latest, type of update)
- Lockfile Status (clean or issues found)
- Abandoned Packages (no updates in 2+ years)

Append to shared-context.md:
- Packages needing urgent updates
- Any dependency conflicts that affect other agents"
```

## Resilience Patterns

### Failure Recovery

Scheduled agents should be resilient to common failure modes:

```bash
# Retry logic for the Copilot CLI call
MAX_RETRIES=2
RETRY_COUNT=0

while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
  if copilot -p "$PROMPT" > "$REPORT_FILE" 2>&1; then
    break
  fi
  RETRY_COUNT=$((RETRY_COUNT + 1))
  echo "[$(date)] Attempt $RETRY_COUNT failed. Retrying..."
  sleep 10
done

if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then
  echo "[$(date)] $AGENT_NAME FAILED after $MAX_RETRIES attempts" >> "$REPORT_FILE"
fi
```

### WIP Limits

For agents that produce work items requiring human review (like research or planning agents), enforce a WIP limit to prevent accumulating more unreviewed work than humans can handle:

```bash
# Check how many items are pending review before starting new work
PENDING_COUNT=$(ls docs/agents/pending-review/ 2>/dev/null | wc -l)
WIP_LIMIT=5

if [ "$PENDING_COUNT" -ge "$WIP_LIMIT" ]; then
  echo "[$(date)] WIP limit reached ($PENDING_COUNT/$WIP_LIMIT). Skipping run."
  exit 0
fi
```

### Stagger Schedules

Don't run multiple agents at the same time. If they write to the same shared context file, they can conflict. Stagger by at least 15 minutes:

| Agent | Schedule |
|-------|----------|
| Test health | Daily 6:00 AM |
| Code quality | Daily 6:15 AM |
| Security audit | Weekly Monday 6:30 AM |
| Dependency health | Weekly Monday 6:45 AM |

## Shared Context System

The shared context file (`docs/agents/shared-context.md`) is a cross-agent intelligence workspace. Every scheduled agent:

1. **Reads** it before starting — to build on other agents' findings
2. **Writes** to it after finishing — to share discoveries

### Format

```markdown
<!-- ENTRY:START agent=agent-name timestamp=2024-01-15T06:00:00Z -->
## Agent Name — 2024-01-15
- **Status**: GREEN / YELLOW / RED
- Key findings (bullet points)
- Metrics (numbers, percentages)

**Cross-agent recommendations:**
- [Other Agent]: specific actionable recommendation
<!-- ENTRY:END -->
```

### Rules

1. **Maximum 3 entries per agent type.** Oldest entry is removed when a new one is added.
2. **Cross-agent recommendations are mandatory.** If findings affect another agent's domain, say so explicitly.
3. **Be specific.** "Security looks fine" is useless. "No injection vectors found — all user input escaped via `sanitize()`" is useful.

## Prerequisites

- Copilot CLI installed and authenticated (`copilot --version`)
- Project dependencies installed (agents may run test/build commands)
- `docs/agents/` directory exists in the project
- `logs/` directory exists for output capture

### CLI Authentication for Cron

When running `copilot -p` from cron or launchd, the CLI must be pre-authenticated. Unlike interactive sessions where the IDE handles auth, headless mode requires:

1. **Run `copilot auth` once interactively** to cache credentials
2. **Verify cron has access to the credential store** — test by running your agent script manually from a non-interactive shell: `bash -l scripts/agents/my-agent.sh`
3. **Set `PATH` explicitly in cron** — cron doesn't inherit your shell profile. Add the full path to the `copilot` binary or source your profile in the agent script.
